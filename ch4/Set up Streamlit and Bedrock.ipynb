{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca808445",
   "metadata": {},
   "source": [
    "# Run Streamlit and Bedrock on SageMaker notebook instance\n",
    "\n",
    "This notebook was built using the conda PyTorch 3.10 kernel on an `ml.t3.medium` instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d9dc81",
   "metadata": {},
   "source": [
    "### Step 1. Install Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8530bd42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87271af",
   "metadata": {},
   "source": [
    "### Step 2. Write a minimal Streamlit app with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a055581",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile language_app.py\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "def add_to_session_history(role, content):\n",
    "    st.session_state.messages.append({\"role\": role, \"content\": content})\n",
    "    \n",
    "\n",
    "# this adds a title to the application\n",
    "st.title('My first language application')\n",
    "\n",
    "# create a local list to hold the mesage history\n",
    "st.session_state.messages = []\n",
    "\n",
    "\n",
    "# this prints all the messages in the history\n",
    "for msg in st.session_state.messages:\n",
    "    with st.chat_message(msg['role']):\n",
    "        st.markdown(msg['content'])\n",
    "\n",
    "# this creates a template on the screen and a variable in the script\n",
    "prompt = st.chat_input('This is where you put your questions')\n",
    "\n",
    "if prompt:\n",
    "    \n",
    "    st.chat_message('user').markdown(prompt)\n",
    "    \n",
    "    add_to_session_history('user', prompt)\n",
    "    \n",
    "    res = f'I heard you say: {prompt}'\n",
    "    \n",
    "    with st.chat_message('assistant'):\n",
    "        st.markdown(res)\n",
    "        \n",
    "    add_to_session_history('assistant', res)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f388b55f",
   "metadata": {},
   "source": [
    "Remember, to view this in your SageMaker notebook instance you'll need to follow a few steps.\n",
    "1. Copy the url you see above for your notebook instance.\n",
    "2. After the `sagemaker.aws/` part of the url, add `proxy/8501/`. This port number, here `8501`, will change when you run additional Streamlit apps. Each time you invoke `streamlit run <>`, Streamlit will tell you which port to use in the output. Make sure you use that number when you update the url.\n",
    "3. Open a new tab in your web browswer, preferably one with a light background, and paste this in! You'll need to be logged in to your AWS account in that web browser to access this.\n",
    "4. Every time you modify this script, just remember to stop your Kernel and run the command again below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1639a369",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!streamlit run language_app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a7e36e-0ba2-453c-abe0-3b5f432bb612",
   "metadata": {},
   "source": [
    "Before you move onto step 3, stop your Jupyter kernel. You can open up a terminal and run the commandss `pip install streamlit && streamlit run language_app.py` to keep the front end active if you like."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d8356b",
   "metadata": {},
   "source": [
    "### Step 3. Test your Bedrock connection\n",
    "Before continuing, make sure the IAM role you are using has access to Bedrock. Go do this now by updating the SageMaker execution role in the IAM console within AWS now if you don't already have this. Once you've added the relevant permissions, come back here and test the Bedrock connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6cda37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "bedrock_client = boto3.client('bedrock-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c07a707",
   "metadata": {},
   "source": [
    "Bedrock uses a `Messages` API, meaning it is explicitly looking for a list of messages in order to respond. This is helpful because it simplifies the development for chat!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ccda95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages=[{ \"role\":'user', \n",
    "           \"content\":[{'type':'text',\n",
    "                       'text': \"What does it mean to train a language model?\"}]}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a1121d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "body = json.dumps(\n",
    "        {\n",
    "            \"max_tokens\": 100,\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": 0.5,\n",
    "            \"top_p\": 1,\n",
    "            # you'll need to pass an anthropic version here\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",    \n",
    "\n",
    "        }  \n",
    "    )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0fca0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = bedrock_client.invoke_model(body=body, \n",
    "                                       # also pass a model ID here\n",
    "                                       modelId=\"anthropic.claude-3-sonnet-20240229-v1:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c8b8fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response_body = json.loads(response.get('body').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92a9424",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "response_body['content'][0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc06440b",
   "metadata": {},
   "source": [
    "### Step 4. Connect Bedrock to Streamlit\n",
    "Now that you have a connection to Bedrock working, let's integrate this into our minimal Streamlit application. This will be a few key steps.\n",
    "1. Initialize the chat history with a system message, giving the language model some high level context. \n",
    "2. Capture incoming messages from the customer.\n",
    "3. Format the messages to invoke Bedrock\n",
    "4. Send the messages and receive the response\n",
    "5. Send the response to the customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e683ad0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile bedrock_language_app.py\n",
    "\n",
    "import streamlit as st\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "def add_to_session_history(role, content):\n",
    "    st.session_state.messages.append({\"role\": role, \"content\": content})\n",
    "\n",
    "def initialize_msg_history():\n",
    "    # create a local list to hold the mesage history\n",
    "    st.session_state.messages = []\n",
    "\n",
    "def send_to_bedrock(bedrock_client):\n",
    "    \n",
    "    bedrock_messages = st.session_state.messages\n",
    "\n",
    "    body = json.dumps({ \"max_tokens\": 512,\n",
    "                    \"messages\": bedrock_messages,\n",
    "                    \"temperature\": 0.5,\n",
    "                    \"top_p\": 1,\n",
    "                    \"anthropic_version\": \"bedrock-2023-05-31\"})  \n",
    "    \n",
    "    response = bedrock_client.invoke_model(body=body, modelId=\"anthropic.claude-3-sonnet-20240229-v1:0\")\n",
    "    \n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    \n",
    "    return response_body['content'][0]['text']\n",
    "    \n",
    "                                \n",
    "def handle_prompt(prompt, bedrock_client):\n",
    "    \n",
    "    st.chat_message('user').markdown(prompt)\n",
    "\n",
    "    add_to_session_history('user', prompt)\n",
    "\n",
    "    # this looks in the local session state history managed by Streamlit \n",
    "    res = send_to_bedrock(bedrock_client)\n",
    "\n",
    "    with st.chat_message('assistant'):\n",
    "        st.markdown(res)\n",
    "\n",
    "    add_to_session_history('assistant', res)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # this adds a title to the application\n",
    "    st.title('My Bedrock language application')\n",
    "    \n",
    "    initialize_msg_history()\n",
    "\n",
    "    # do this once per session\n",
    "    bedrock_client = boto3.client('bedrock-runtime')\n",
    "\n",
    "    # this creates a template on the screen and a variable in the script\n",
    "    prompt = st.chat_input('This is where you put your questions')\n",
    "\n",
    "    # is triggered when the user hits enter in the on-screen widget\n",
    "    if prompt:\n",
    "\n",
    "        handle_prompt(prompt, bedrock_client)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "168e0e4e-3d75-4fba-8a53-f1f35b8d4362",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
      "\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.16.64.209:8502\u001b[0m\n",
      "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.203.37.48:8502\u001b[0m\n",
      "\u001b[0m\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!streamlit run bedrock_language_app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b957992-10ff-4be5-9844-1b8828052a96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
